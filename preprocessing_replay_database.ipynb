{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import cv2\n",
    "import dlib\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('pretrained_detection_models/shape_predictor_68_face_landmarks.dat')\n",
    "detector = cv2.CascadeClassifier('pretrained_detection_models/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PATH = 'data/train/attack/fixed/attack_highdef_client108_session01_highdef_video_controlled.mov'\n",
    "PROTOCOLS = 'data/protocols'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_to_np(shape, dtype=\"int\"):\n",
    "    coords = np.zeros((68, 2), dtype=dtype)\n",
    "    for i in range(0, 68):\n",
    "        coords[i] = (shape.part(i).x, shape.part(i).y)\n",
    "    return coords\n",
    "\n",
    "class FaceAligner:\n",
    "    def __init__(self, predictor, desired_left_eye=(0.35, 0.35),\n",
    "        desired_face_width=256, desired_face_height=256):\n",
    "        \n",
    "        self.predictor = predictor\n",
    "        self.desired_left_eye = desired_left_eye\n",
    "        self.desired_face_width = desired_face_width\n",
    "        self.desired_face_height = desired_face_height\n",
    "\n",
    "    def align(self, image, gray, face_bbox):\n",
    "        \n",
    "        x, y, face_width, face_height = int(face_bbox[0]), int(face_bbox[1]), int(face_bbox[2]), int(face_bbox[3])\n",
    "        shape = self.predictor(gray,dlib.rectangle(x, y, x + face_width, y + face_height))\n",
    "        shape = shape_to_np(shape)\n",
    "\n",
    "        # extract the left and right eye (x, y)-coordinates\n",
    "        right_eye_points = shape[36:42]\n",
    "        left_eye_points = shape[42:48]\n",
    "\n",
    "        # compute the center of mass for each eye\n",
    "        left_eye_center = left_eye_points.mean(axis=0).astype(\"int\")\n",
    "        right_eye_center = right_eye_points.mean(axis=0).astype(\"int\")\n",
    "\n",
    "        # compute the angle between the eye centroids\n",
    "        dy = right_eye_center[1] - left_eye_center[1]\n",
    "        dx = right_eye_center[0] - left_eye_center[0]\n",
    "        angle = np.degrees(np.arctan2(dy, dx)) - 180\n",
    "\n",
    "        # compute the desired right eye x-coordinate based on the\n",
    "        # desired x-coordinate of the left eye\n",
    "        desired_right_eye_x = 1.0 - self.desired_left_eye[0]\n",
    "\n",
    "        # determine the scale of the new resulting image by taking\n",
    "        # the ratio of the distance between eyes in the *current*\n",
    "        # image to the ratio of distance between eyes in the\n",
    "        # *desired* image\n",
    "        distance = np.sqrt((dx ** 2) + (dy ** 2))\n",
    "        desired_distance = (desired_right_eye_x - self.desired_left_eye[0])\n",
    "        desired_distance *= self.desired_face_width\n",
    "        scale = desired_distance / distance\n",
    "\n",
    "        # compute center (x, y)-coordinates (i.e., the median point)\n",
    "        # between the two eyes in the input image\n",
    "        eyes_center = ((left_eye_center[0] + right_eye_center[0]) // 2,\n",
    "            (left_eye_center[1] + right_eye_center[1]) // 2)\n",
    "\n",
    "        # grab the rotation matrix for rotating and scaling the face\n",
    "        M = cv2.getRotationMatrix2D( eyes_center, angle, scale)\n",
    "\n",
    "        # update the translation component of the matrix\n",
    "        tx = self.desired_face_width * 0.5\n",
    "        ty = self.desired_face_height * self.desired_left_eye[1]\n",
    "        M[0, 2] += (tx - eyes_center[0])\n",
    "        M[1, 2] += (ty - eyes_center[1])\n",
    "\n",
    "        # apply the affine transformation\n",
    "        (w, h) = (self.desired_face_width, self.desired_face_height)\n",
    "        aligned_face = cv2.warpAffine(image, M, (w, h),\n",
    "            flags=cv2.INTER_CUBIC)\n",
    "\n",
    "        # return the aligned face\n",
    "        return aligned_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_aligner = FaceAligner(predictor, (0.31,0.31),224,224)\n",
    "def crop_face(image):\n",
    "    gray_image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    detected = detector.detectMultiScale(gray_image, 1.1, 5)\n",
    "    if len(detected) == 0:\n",
    "        return None\n",
    "    face_bbox = detector.detectMultiScale(gray_image, 1.1, 5)[0]\n",
    "    #x, y, width, height = face_bbox[0], face_bbox[1], face_bbox[2], face_bbox[3]\n",
    "    # return cv2.resize(image[y:y+height, x:x+width,:],(224,224))\n",
    "    face_aligned = face_aligner.align(image, gray_image, face_bbox)\n",
    "    return face_aligned\n",
    "\n",
    "def extract_frames(video_path, out_path):\n",
    "    count = 0\n",
    "    capture = cv2.VideoCapture(video_path)\n",
    "    is_captured, image = capture.read()\n",
    "    while is_captured:\n",
    "        face = crop_face(image)\n",
    "        if face is not None:\n",
    "            cv2.imwrite(out_path + os.path.basename(video_path)[:-4] + \"_frame%d.jpg\" % count,face) \n",
    "        capture.set(cv2.CAP_PROP_POS_MSEC,(count*500))\n",
    "        is_captured, image = capture.read()\n",
    "        count += 1\n",
    "    capture.release()\n",
    "    \n",
    "def process_videos(video_pathes,out_path):\n",
    "    for path in tqdm_notebook(video_pathes):\n",
    "        extract_frames(path,out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "video_pathes = []\n",
    "with open(PROTOCOLS + '/real-test.txt') as file:\n",
    "    video_pathes = file.read().split('\\n')\n",
    "    \n",
    "print(len(video_pathes))\n",
    "\n",
    "process_videos(video_pathes,'replay_attack_data_prepared/test/real/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "video_pathes = []\n",
    "with open(PROTOCOLS + '/attack-video-allsupports-test.txt') as file:\n",
    "    video_pathes = file.read().split('\\n')\n",
    "    \n",
    "print(len(video_pathes))\n",
    "\n",
    "process_videos(video_pathes,'data/test/video_attack/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "video_pathes = []\n",
    "with open(PROTOCOLS + '/attack-photo-allsupports-test.txt') as file:\n",
    "    video_pathes = file.read().split('\\n')\n",
    "    \n",
    "print(len(video_pathes))\n",
    "\n",
    "process_videos(video_pathes,'data/test/photo_attack/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e100acc6da343b7a5c84db5e3fc695a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=60), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "120\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe6b2a9568f14e0193228b5bff95c17d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=120), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "180\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "353bc25cac9a4faea03ff14e81a11671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=180), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 17min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "video_pathes = []\n",
    "with open(PROTOCOLS + '/real-devel.txt') as file:\n",
    "    video_pathes = file.read().split('\\n')\n",
    "    \n",
    "print(len(video_pathes))\n",
    "\n",
    "process_videos(video_pathes,'data/devel/real/')\n",
    "\n",
    "\n",
    "video_pathes = []\n",
    "with open(PROTOCOLS + '/attack-video-allsupports-devel.txt') as file:\n",
    "    video_pathes = file.read().split('\\n')\n",
    "    \n",
    "print(len(video_pathes))\n",
    "\n",
    "process_videos(video_pathes,'data/devel/video_attack/')\n",
    "\n",
    "\n",
    "video_pathes = []\n",
    "with open(PROTOCOLS + '/attack-photo-allsupports-devel.txt') as file:\n",
    "    video_pathes = file.read().split('\\n')\n",
    "    \n",
    "print(len(video_pathes))\n",
    "\n",
    "process_videos(video_pathes,'data/devel/photo_attack/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
